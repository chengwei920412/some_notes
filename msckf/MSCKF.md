# MSCKF(双目)

### 视觉前端

- 获取双目图像,建立图像金字塔,用来作为之后的LK光流跟踪的输入数据.
  - 创建图像金字塔.
- 如果第一帧图像,则第一帧图像是用于初始化,调用initializeFirstFrame()函数进行初始化.
  - 提取FAST关键点.
  - 光流跟踪匹配两帧的关键点.(这个时候算出了IMU的第一帧左右两张图像之间的姿态变换)调用了stereoMatch()函数(这个函数用的是左右两张图像)
    - 计算左图像中的关键点位置矫正.**(矫正后的点是归一化平面坐标下的点)(这里用到了IMU计算的左右两张图像之间的姿态变换作为一个初值)**
    - 然后计算左图像在右图像上的位置**(这个目的是在后面的光流法中给定一个初值)**.
    - 使用LK光流跟踪关键点,输出右图像上的匹配点.
    - 判断跟踪的点是否已经超出图像范围.
    - 然后根据IMU的数据计算第一帧左右两张图像之间的姿态变换关系,计算本质矩阵. 
    - 两帧图像点去畸变.
    - 剔除明显不符合对极几何的点.
  - 保存符合要求的inliers和响应强度.
  - 图像画格子(默认是4x4的格子),分别分配到各个格子中,格子中保存的是检测到的特征点信息(第一帧左右两张图像中的位置以及响应强度)
  - 按照特征点响应对格子中所有特征点进行排序.
  - 按照预设的阈值对每个格子保留特征点
    - 将当前的关键点保存到curr_features_ptr
    - 按照响应值从大到小取指定的特征点.
  - 显示双目图像,并发布消息.
- 如果不是第一帧图像.
  - 调用trackFeatures()函数.**(在trackFeatures()函数中,主要实现特征点的跟踪,过滤误差较大,不稳定的outliers.追踪方法有三种:LK光流跟踪,双目匹配,two-point RANSAC.)**
    - 根据IMU的信息对前后时刻的图像的旋转计算得到一个初值.
      - 找到上一时刻和当前时刻的IMU对应的时间戳.
      - 计算平均角速度.
      - 将平均角速度从IMU系转换到图像坐标系.
      - 通过IMU来计算前后两个时刻两帧图像之间的旋转.
      - 清楚已使用过的IMU信息.
    - 获取前一时刻的双目图像特征的信息.(假如是初始化的第一帧中的图像,则这里面的点就是第一帧左右两张图像所匹配的点)
    - 根据IMU计算得到的旋转值以及单应性原理来预测当前帧的关键帧位置.
      - 通过IMU计算出来的两帧之间的姿态关系计算本质矩阵**(只不过这个本质矩阵没有t,这有两个原因,一个是假设两帧相差时间很短,忽略了深度的差异,公式为$KRK^{-1}$)(所以在无人机这种项目中,因为无人机的速度很快,位移不能忽略,所以应该将t也加入进去)**
      - 然后通过这个本质矩阵计算出Homography矩阵.
      - 通过H矩阵计算出上一帧图像上左图的点在这一帧图像上左图上的位置.**(这个过程中并没有考虑到图像的畸变,所以只是一个粗略的预测)**
    - 通过LK光流对上一时刻的关键点位置做跟踪匹配(这里用到了上一步算出的投影位置作为初值)
    - 过滤在图像外的点,然后就是过滤outlier.(过滤outlier有三步,第一步是双目匹配当前帧的左图和右图,第二步是RANSAC过滤上一帧和当前帧的左图,第三步是RANSAC过滤上一帧和当前帧的右图)
    - 第一步,对当前双目进行匹配,调用stereoMatch()函数,取出outliers.
    - 第二步,对同一个相机的不同时刻做RANSAC剔除外点.
      - 计算两个相机的平均焦距,倒数为一个像素点的归一化坐标值偏差.(因为是双目,所以需要计算平均焦距)
      - 对前后所有的关键点进行去畸变操作.
      - 乘上帧间的旋转使上一时刻与当前时刻的关键点之间只有平移量.
      - 归一化关键点,获得尺度因子,归一化坐标值偏差也需要乘以尺度因子.
      - 计算前后两帧匹配的关键点的差值.
      - 计算关键点差值的平均值,将差值大于阈值的点视为外点剔除.
        - 如果内点数目小于3,则认为所有的输入都是outliers.这种情况发生在速度较大的旋转并且只有很少的feature跟踪到.
      - 检测运动是否退化.(退化表示帧间的平移量几乎为0,这里平均的差值小于1个像素则认为是退化)
      - 接下来就是two-RANSAC方法.
        - 因为$x_2^T\hat{t}Rx_1 = 0$且$x_1'=Rx_1$则推出$x_2^T\hat{t}x_1'=0$
        - 任取前后两帧中的两个匹配关键点,则可以构建一个矩阵方程组$AX=b$
        - 求出$t$,计算各个匹配点的误差,获取inliers.
        - 获得一个内点集,用内点集使用最小二乘的方法计算一个模型,获得内点集的误差总和.
        - 重复上面的过程,选择误差总和最小的内点集.
    - 计算RANSAC后特征点数量.
    - 计算RANSAC的比例.
  - 调用addNewFeatures()函数将新的特征放入当前图像.(如果一直tracking的话,那么随着时间流逝,有些特征会消失,有些可能也会有累计误差,所以我们势必要添加一些新的特征,这个步骤是在跟踪上一帧特征之后要做的,因为stereoMatching()函数和twoPointRansac()函数都会剔除一些outliers,所以我们需要提取新的特征保证能一直运行下去)
    - 建立mask,防止重复检测特征点.(这个mask的范围是特征点的[-2,3]范围内)
    - 检测新的特征点,并将新特征点分配到每个网格,然后按照每个网格特征点的响应排序,使得每个网络特征点的数量不超过网格特征点最大数量限制且不超过本身包含的特征点数量限制.
    - 调用stereoMatch()函数做双目匹配.(获取这一帧左右两张图像中的特征点.)
    - 判断匹配的特征点是不是少于5,或者检测的特征点和匹配的特征点的比例小于0.1.
    - 将新的特征点放入grid里面.
    - 每个grid里面的特征点根据response进行排序.
    - 对每个grid里面进行增加特征点操作,但是增加之后的特征点数量必须小于网格特征点数量最小值.
  - 调用pruneGridFeatures()函数,将grid里面跟踪次数过少的特征点去除.**(首先将curr_features_ptr中每个格子内的特征根据连续跟踪次数排序,如果这个格子内的特征点数目m超过grid_max_feature_num,则去除(m-grid_max_feature_num)个点)**
  - 调用drawFeaturesStereo()函数显示图像结果.
- 将特征点进行去畸变,转化为归一化坐标,调用publish()函数发布了当前特征点的信息.

### MSCKF文件

- 调用initialize()函数.
  - 加载参数.
  - 初始化$Q$矩阵.($Q$矩阵是运动噪声协方差矩阵)
  - 初始化卡方校验表.
  - 创建ROS相关IO.
- 调用imuCallback()函数.
  - 保存IMU数据到$IMU\_msg\_buffer$中.**(这样没有立即传输,可以处理传输延时)**
  - 如果没有重力向量,则初始化重力向量,同时初始化系统第一帧相对重力的变换.**(在系统开始运行后,在一定数量的IMU数据基础上初始化IMU的偏置和初始方向.)(因为s-msckf默认是从静止状态进行初始化的,所以就用加速度平均值初始化重力,角速度平均值初始化角速度偏置)**
    - 累计当前缓存中的IMU角速度和线性加速度.
    - 陀螺仪的偏置为所有初始IMU数据的平均值.
    - 利用加速度平均值初始化重力.**(得到重力向量后构建世界坐标系, 令重力方向为z轴负方向, 然后定义惯性系相对于世界坐标系的朝向)**





### 公式推导

$I$:IMU机体坐标系

$G$:惯性坐标系

$C$:相机坐标系

作为一个滤波器,滤波器的状态向量有两个部分,分别为IMU状态和Camera状态,
$$
\mathbf{x}_I=[^I_G\mathbf{q}^T\ \mathbf{b}_g^T\ ^{G} \mathbf{v}_{I}^{T}\ \mathbf{b}_{a}^{T} \ ^{G} \mathbf{p}_{I}^{T}\ _{C}^{I} \mathbf{q}^{T} \ ^I{\mathbf{p}_{C}^{T}}]^T
$$
$^{I}_{G} \mathbf{q}$表示的是从惯性系到机体IMU的旋转变换,$^{G} \mathbf{v}_{I}$和$^{G} \mathbf{p}_{I}$分别表示机体在惯性系下的速度和位置,$^{I}_{C} \mathbf{q}$和$^{I} \mathbf{p}_{C}$分别代表从相机坐标系到IMU坐标系的旋转和平移,以左相机为准.

误差状态为,


$$
\tilde{\mathbf{x}}_I=[^I_G\tilde{\mathbf{\theta}}^T\ \tilde{\mathbf{b}}_g^T\ ^{G} \tilde{\mathbf{v}}^{T}\ \tilde{\mathbf{b}}_{a}^{T} \ ^{G} \tilde{\mathbf{p}}_{I}^{T}\ _{C}^{I} \tilde{\mathbf{\theta}}^{T} \ ^I{\tilde{\mathbf{p}}_{C}^{T}}]^T
$$
对于普通的变量,满足通用的加减关系,但是对于四元数来说,误差四元数为
$$
\delta \mathbf{q}=\mathbf{q} \otimes \hat{\mathbf{q}}^{-1} \approx (\frac{1}{2} {_{I}^{G}\tilde{\boldsymbol{\theta}}^{T}} \ 1)^T
$$
其中$_{I}^{G} \tilde{\boldsymbol{\theta}}^{T} \in \mathbb{R}^{3}$表示一个微小的旋转,通过这种方式将旋转误差降到了三维.考虑到最终的误差状态向量,设有N个相机状态,则最终的误差状态向量为
$$
\tilde{\mathbf{x}}=\left(\begin{array}{cccc}{\tilde{\mathbf{x}}_{I}^{T}} & {\tilde{\mathbf{x}}_{C_{1}}} & {\dots} & {\tilde{\mathbf{x}}_{C_{N}} )^{T}}\end{array}\right.
$$

$$
\tilde{\mathbf{x}}_{C_{i}}=\left(\begin{array}{cc}{^{C_{i}}_{G}}  {\tilde{\boldsymbol{\theta}}^{T}} & ^{G}  {\tilde{\mathbf{p}}_{C_{i}}^{T}}\end{array}\right)^{T}
$$

### 例子

以下图为例,状态向量包含5个相机的位姿$T_{1\sim5}$和当前时刻的位姿$X_{I M U_{5}}$,其中$X_{I M U_{5}}$和$T_5$均表示当前时刻的状态,只不过局部坐标系不同,一个是IMU系,一个是Camera系,两者通过图中红色方块的外参进行约束.另外,黄色小块为IMU预测因子,蓝色小块为视觉更新因子.值得注意的是,**图中的路标点$f_{1\sim3}$未放入到优化变量中,而是通过足够多的**
**KF对路标点进行三角化,并相信三角化的结果是准确的,从而将其固定住并边缘化掉,将边缘化后的影响作为先验约束加入到滑窗内的共视相机位姿上,再进行视觉更新.**

下图会用$f_1$和$f_2$这两个路标点进行视觉更新,$f_1$是因为太老,被滑窗所有帧都看见;$f_2$是不被当前帧$T_5$所观测到了,$f_3$因为还能被当前帧观测到,且不算太老,所以留在窗口中继续跟踪.

![](/home/liu/Documents/some_notes/msckf/MSCKF_optimize_variants.png)

优化变量的数学形式为
$$
X_{k}(16+7 N) \times 1=[X_{IMU_k}\  {^{C_1}_G\overline{q}} \ {^Gp_{C_1}} \ ... \ {^{C_N}_G\overline{q}} \ {^Gp_{C_N}}]
$$
其中,$^{C_{1}}_G \overline{q}=\overline{q}_{C_{1} \leftarrow G}$为归一化四元数,$^{G} p_{C_{1}}=p_{G \leftarrow C_{1}}$注意旋转和平移的坐标系方向相反,第k帧的优化变量$X_{IMU_{k}}$为,
$$
X_{I M U_{k}}^{16 \times 1}=\left[\begin{array}{lll}^{I}_G {\overline{q}} & {b_{g}} & {^{G} v_{I}} & {b_{a}} & {p_{I}}\end{array}\right]^{T}
$$

$$
T_{i}^{7 \times 1}=\left[\begin{array}{ll}^{C_i}_G {\overline{q}} & {^{G} p_{C_{i}}}\end{array}\right]^{T}
$$

严格来说,优化变量矩阵中的各元素右上角也应加上转置符号"T",即优化变量为多行一列排布,这里为了形式上简单,不严禁地省去了转置符号,仅在整体矩阵外面加上转置.

MSCKF在预测和更新时的处理对象为误差状态向量,并非上面的实际状态向量,理由有以下四个:

- 朝向用四元数表示是过参的,但是角度误差的参数只有3个,与自由度是一致的.
- 